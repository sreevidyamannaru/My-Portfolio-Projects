
# Big Data Pipeline

An ETL pipeline built with PySpark to process large datasets.

## Steps to Run

1. Install PySpark:
   ```
   pip install pyspark
   ```
2. Run the scripts in the following order:
   - `data_ingestion.py` to read data.
   - `transformations.py` to transform the data.
   - `export.py` to save the results.
            